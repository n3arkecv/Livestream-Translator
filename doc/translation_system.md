# ğŸŒ Translation System Design â€” Real-Time YouTube Live Translation App
---

## ğŸ§© 1. ç³»çµ±å®šä½

**Translation System** æ˜¯æ ¸å¿ƒä¸»æµç¨‹çš„ç¬¬äºŒéšæ®µï¼Œ
è² è²¬å°‡ STT æ¨¡çµ„ç”¢å‡ºçš„å®Œæ•´å¥ï¼ˆ`final_sentence`ï¼‰å³æ™‚ç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼Œ
ä¸¦æ ¹æ“šèªå¢ƒç¶­æŒçŸ­ç¯‡è¨˜æ†¶ï¼ˆScenario Contextï¼‰ï¼Œç¢ºä¿é€£è²«èªæ„ã€‚

æ¶æ§‹ä¸»è¦åˆ†ç‚ºä¸‰å±¤ï¼š

| å±¤ç´š          | çµ„ä»¶                           | èªªæ˜                      |
| ----------- | ---------------------------- | ----------------------- |
| ä¸Šå±¤ (Input)  | **STT Output Handler**       | æ¥æ”¶å®Œæ•´å¥ï¼ˆFinal Sentenceï¼‰äº‹ä»¶ |
| ä¸­å±¤ (Core)   | **LLM1 ç¿»è­¯æ ¸å¿ƒ**ã€**LLM2 èªå¢ƒæ›´æ–°å™¨** | è² è²¬ç¿»è­¯èˆ‡èªå¢ƒè¨˜æ†¶ç¶­è­·             |
| ä¸‹å±¤ (Output) | **Overlay**ã€**Dialogue Log** | é¡¯ç¤ºç¿»è­¯çµæœèˆ‡å„²å­˜èªæ–™             |

---

## ğŸ§  2. ç¿»è­¯æµç¨‹æ¦‚è¿°

```text
[Fully Transcribed Sentence] + [Scenario Context]
    â†“
[LLM1: ç¿»è­¯è™•ç†]
    â†“
[Translated Sentence] â†’ Display Translated Sentence
    â†“
[åŸå§‹ Scenario Context] + [Translated Sentence]
    â†“
[LLM2: æƒ…å¢ƒæ›´æ–°è™•ç†]
    â†“
[New Scenario Context]
    â†“
[å„²å­˜è‡³ Dialogue Log]
```

* **LLM1** è¼¸å…¥ï¼š**Scenario Context** + **Fully Transcribed Sentence**ï¼Œè¼¸å‡ºï¼š**Translated Sentence**
* **LLM2** è¼¸å…¥ï¼š**åŸå§‹ Scenario Context** + **Translated Sentence**ï¼Œè¼¸å‡ºï¼š**New Scenario Context**
* Scenario Context åƒ…ä¿ç•™æœ€è¿‘ 200â€“500 tokensï¼Œç¶­æŒè¨˜æ†¶èˆ‡æ•ˆèƒ½å¹³è¡¡ã€‚

---

## âš™ï¸ 3. æ¨¡çµ„åˆ†å±¤è¨­è¨ˆ

| æ¨¡çµ„åç¨±                   | è§’è‰²  | åŠŸèƒ½æ‘˜è¦                                   |
| ---------------------- | --- | -------------------------------------- |
| **TranslationManager** | æ§åˆ¶å±¤ | ä¸²æ¥ STTã€LLM1ã€LLM2ï¼Œç®¡ç†ç¿»è­¯ä»»å‹™                |
| **LLMClient**          | é€šè¨Šå±¤ | å‘¼å« OpenAI APIï¼ˆgpt-4.1-mini-2025-04-14ï¼‰ |
| **ContextManager**     | è¨˜æ†¶å±¤ | ç¶­è­·èˆ‡è£å‰ª Scenario Context                 |
| **PromptBuilder**      | çµ„åˆå±¤ | å‹•æ…‹æ§‹å»º promptï¼ˆèªå¢ƒ + å¥å­ + ç¿»è­¯æŒ‡ç¤ºï¼‰            |
| **DialogueRecorder**   | è¼¸å‡ºå±¤ | å¯«å…¥ Dialogue Log æª”æ¡ˆ                     |
| **LatencyTracker**     | ç›£æ¸¬å±¤ | è¨ˆç®— LLM å»¶é²ä¸¦ä¸Šå ± System Log                |

---

## ğŸ§© 4. æ¨¡çµ„äº’å‹•æµç¨‹

| æ­¥é©Ÿ | äº‹ä»¶                             | è™•ç†æ¨¡çµ„               | çµæœ             |
| -- | ------------------------------ | ------------------ | -------------- |
| 1  | `stt.final_sentence`           | TranslationManager | æ”¶åˆ°å®Œæ•´å¥          |
| 2  | `llm1.translate_started`       | LLMClient          | å‘ API ç™¼å‡ºç¿»è­¯è«‹æ±‚   |
| 3  | `llm1.translate_finished`      | LLMClient          | å›å‚³è­¯æ–‡èˆ‡ Token çµ±è¨ˆ |
| 4  | `llm2.context_update_started`  | ContextManager     | å–å¾—èˆŠèªå¢ƒï¼Œæº–å‚™æ›´æ–°     |
| 5  | `llm2.context_update_finished` | ContextManager     | æ–°èªå¢ƒç”¢ç”Ÿã€è£å‰ª       |
| 6  | `overlay.translation_rendered` | Overlay            | é¡¯ç¤ºç¿»è­¯           |
| 7  | `dialogue.record_appended`     | DialogueRecorder   | å¯«å…¥å°è©±è³‡æ–™         |
| 8  | `syslog.info`                  | SystemLog          | è¨˜éŒ„å»¶é²èˆ‡ token ç”¨é‡ |

---

## ğŸ’¬ 5. Prompt è¨­è¨ˆï¼ˆLLM1 ç¿»è­¯ï¼‰

### è¼¸å…¥çµ„åˆï¼š
- **Scenario Context** + **Fully Transcribed Sentence**

### ç›®æ¨™èªè¨€ï¼š

* **è‹±æ–‡ â†’ ç¹é«”ä¸­æ–‡**
* **æ—¥æ–‡ â†’ ç¹é«”ä¸­æ–‡**

### PromptBuilder è¼¸å‡ºæ¨£å¼ï¼š

```text
You are a real-time translation assistant.
Translate the following sentence into Traditional Chinese accurately
while preserving tone, subject, and context.

Scenario Context:
{scenario_context}

Sentence to Translate:
"{fully_transcribed_sentence}"

Output only the translation, without explanation.
```

### ç¯„ä¾‹ï¼š

```text
Scenario Context:
è¬›è€…æ­£åœ¨ä»‹ç´¹æ–°ç”¢å“çš„åŠŸèƒ½ï¼Œå‰ä¸€å¥æåˆ°åƒ¹æ ¼å¯¦æƒ ã€‚

Sentence to Translate:
"This feature allows users to control everything from one dashboard."

â†’ Output:
ã€Œé€™é …åŠŸèƒ½è®“ä½¿ç”¨è€…èƒ½å¾å–®ä¸€å„€è¡¨æ¿æ§åˆ¶æ‰€æœ‰è¨­å®šã€‚ã€
```

---

## ğŸ§© 6. Prompt è¨­è¨ˆï¼ˆLLM2 èªå¢ƒæ›´æ–°ï¼‰

### è¼¸å…¥çµ„åˆï¼š
- **åŸå§‹ Scenario Context** + **Translated Sentence**

### åŠŸèƒ½ï¼š

å°‡ã€ŒåŸå§‹æƒ…å¢ƒä¸Šä¸‹æ–‡ + ç¿»è­¯å¾Œçš„å¥å­ã€å£“ç¸®æˆ 200â€“500 tokens çš„æ–°èªå¢ƒæ‘˜è¦ï¼Œ
ç”¨ä»¥ä¿ç•™è©±é¡Œè„ˆçµ¡ã€å£æ°£ã€äººç¨±èˆ‡ä¸»é¡Œå»¶çºŒæ€§ã€‚

### Prompt æ¨¡æ¿ï¼š

```text
You are a summarization assistant.
Update the scenario context to reflect the latest translated sentence.

Previous Context:
{original_scenario_context}

New Translated Sentence:
{translated_sentence}

Return a concise updated context summary (max 500 tokens).
```

---

## ğŸ§® 7. æƒ…å¢ƒç®¡ç†ç­–ç•¥ï¼ˆScenario Contextï¼‰

| é …ç›®   | ç­–ç•¥                       | å¯¦ä½œæ–¹å¼                |
| ---- | ------------------------ | ------------------- |
| ä¿ç•™é•·åº¦ | 200â€“500 tokens           | é™åˆ¶å­—æ•¸å¾Œè£å‰ªèˆŠå…§å®¹ï¼ˆFIFOï¼‰    |
| æ›´æ–°æ™‚æ©Ÿ | æ¯å¥ç¿»è­¯å¾Œ                    | åœ¨ LLM2 å®Œæˆå¾Œè¦†è“‹        |
| æš«å­˜æ–¹å¼ | è¨˜æ†¶é«” + å¿«å–æª”                | JSON æ ¼å¼ï¼ˆå«æ™‚é–“æˆ³ï¼‰       |
| éŒ¯èª¤ä¿è­· | è‹¥æ›´æ–°å¤±æ•—å‰‡ç¶­æŒèˆŠ Context        | ç™¼å‡º `syslog.warning` |
| å°è©±é‡æ’­ | Dialogue Log å¯é‚„åŸ Context | æ¨¡çµ„é–“å…±äº«è®€å–ä»‹é¢           |

---

## âš¡ 8. å»¶é²é ç®—èˆ‡ä½µç™¼ç­–ç•¥

| éšæ®µ            | ç›®æ¨™å»¶é²          | èªªæ˜                |
| ------------- | ------------- | ----------------- |
| STT â†’ LLM1 å•Ÿå‹• | â‰¤ 150 ms      | äº‹ä»¶å‚³éèˆ‡ prompt æ§‹å»º   |
| LLM1 ç¿»è­¯ API   | â‰¤ 700 ms      | gpt-4.1-mini å›å‚³æ™‚é–“ |
| LLM2 æ›´æ–°       | â‰¤ 200 ms      | æ‘˜è¦ç”Ÿæˆ              |
| Overlay é¡¯ç¤º    | â‰¤ 100 ms      | UI æ¸²æŸ“èˆ‡æ’ç¨‹          |
| **ç¸½å»¶é²ç›®æ¨™**     | **0.5â€“1.5 s** | å«ç¶²è·¯æµ®å‹•èˆ‡ I/O        |

### æŠ€è¡“ç­–ç•¥

* TranslationManager ç¶­è­· **async ä»»å‹™æ± **ï¼ŒåŒæ™‚è™•ç†å¤šå¥ã€‚
* è‹¥ backlog éå¤š â†’ ç™¼å‡º `rate_limit.backpressure`ï¼Œæš«ç·©æ–°å¥é€²å…¥ã€‚
* API å¤±æ•— â†’ é‡è©¦ï¼ˆè¦‹ Config.retry è¨­å®šï¼‰ã€‚

---

## ğŸ§¾ 9. Dialogue Log å¯«å…¥æ ¼å¼

æ¯å¥ç¿»è­¯å¾Œå¯«å…¥ä¸€ç­†ï¼ˆç”± DialogueRecorder è™•ç†ï¼‰ï¼š

```json
{
  "timestamp": "2025-11-05T15:42:11Z",
  "session_id": "yt_2025_1105",
  "sentence_id": 27,
  "source_language": "en",
  "source_sentence": "This feature allows users to control everything from one dashboard.",
  "translated_sentence": "é€™é …åŠŸèƒ½è®“ä½¿ç”¨è€…èƒ½å¾å–®ä¸€å„€è¡¨æ¿æ§åˆ¶æ‰€æœ‰è¨­å®šã€‚",
  "scenario_context": "è¬›è€…ä»‹ç´¹æ–°åŠŸèƒ½ï¼Œå»¶çºŒç”¢å“èªªæ˜èªæ°£ã€‚",
  "tokens_in": 38,
  "tokens_out": 45,
  "latency_ms": 812
}
```

> æª”æ¡ˆå¯ç‚º `.jsonl`ï¼ˆæ¯è¡Œä¸€ç­† JSONï¼‰æˆ– `.csv`ï¼›ç”± Dialogue Log æ¨¡çµ„è‡ªå‹•é¸æ“‡ã€‚

---

## ğŸª¶ 10. äº‹ä»¶å°æ‡‰èˆ‡è§¸ç™¼é‚è¼¯

| äº‹ä»¶åç¨±                           | è§¸ç™¼ä¾†æº             | å…§å®¹           | ä¸‹æ¸¸è¡Œç‚º                        |
| ------------------------------ | ---------------- | ------------ | --------------------------- |
| `stt.final_sentence`           | STT æ¨¡çµ„           | å®Œæ•´å¥          | TranslationManager æ¥æ”¶       |
| `llm1.translate_started`       | LLMClient        | sentence_id  | System Log æ¨™è¨˜               |
| `llm1.translate_finished`      | LLMClient        | ç¿»è­¯çµæœ         | Overlay æ›´æ–° + DialogueLog å¯«å…¥ |
| `llm2.context_update_started`  | ContextManager   | èˆŠèªå¢ƒ          | æº–å‚™æ‘˜è¦                        |
| `llm2.context_update_finished` | ContextManager   | æ–°èªå¢ƒ          | Overlay Context æ›´æ–°          |
| `dialogue.record_appended`     | DialogueRecorder | æª”æ¡ˆè·¯å¾‘         | System Log è¨˜éŒ„               |
| `syslog.*`                     | æ‰€æœ‰æ¨¡çµ„             | ç‹€æ…‹ / éŒ¯èª¤ / å»¶é² | GUI é¡¯ç¤º                      |

---

## ğŸ§© 11. é¡åˆ¥ä»‹é¢ï¼ˆä¾›ç¨‹å¼ç”Ÿæˆï¼‰

```python
# translation/manager.py
class TranslationManager:
    def __init__(self, bus, llm_client, context_mgr, recorder, config):
        ...
    async def handle_final_sentence(self, ev: Event[SttFinalSentencePayload]): ...
    async def run_translation(self, sentence: str, lang: str): ...
    async def update_context(self, translated: str): ...

# translation/llm_client.py
class LLMClient:
    async def translate(self, sentence: str, context: str) -> dict: ...
    async def summarize_context(self, old_context: str, translated: str) -> str: ...

# translation/context_manager.py
class ContextManager:
    def __init__(self, max_tokens=500): ...
    def get_context(self) -> str: ...
    def update(self, new_sentence: str, translated: str): ...
    def save_cache(self, path: str): ...

# translation/prompt_builder.py
class PromptBuilder:
    def build_translation_prompt(self, sentence: str, context: str, lang: str) -> str: ...
    def build_summary_prompt(self, context: str, translated: str) -> str: ...

# translation/recorder.py
class DialogueRecorder:
    def append_record(self, record: dict): ...
    def flush(self): ...

# translation/latency_tracker.py
class LatencyTracker:
    def start(self, sentence_id: int): ...
    def stop(self, sentence_id: int) -> int: ...
```

---

## ğŸ§  12. éŒ¯èª¤èˆ‡é‡è©¦é‚è¼¯

| éŒ¯èª¤é¡å‹               | è¡Œç‚º            | äº‹ä»¶                |
| ------------------ | ------------- | ----------------- |
| API è¶…æ™‚             | è‡ªå‹•é‡è©¦ï¼ˆæœ€å¤š 2 æ¬¡ï¼‰  | `retry.scheduled` |
| Token Overflow     | è£å‰ª Contextã€é‡é€ | `syslog.warning`  |
| ç¿»è­¯å¤±æ•—ï¼ˆHTTP 4xx/5xxï¼‰ | è¨˜éŒ„ç©ºç¿»è­¯ä¸¦ä¿ç•™åŸæ–‡    | `syslog.error`    |
| Context æ›´æ–°å¤±æ•—       | ä¿ç•™èˆŠ Context   | `syslog.warning`  |

---

## ğŸ“ˆ 13. æ•ˆèƒ½ç›£æ¸¬èˆ‡åº¦é‡

* **LatencyTracker**ï¼šè¿½è¹¤ LLM1ã€LLM2 æ™‚é–“å·®
* **Metrics æ¨é€**ï¼ˆå¯é¸ï¼‰ï¼šå‚³é€åˆ° Diagnostics é¢æ¿

  * `tokens_in/out`
  * `avg_latency_ms`
  * `context_len`
  * `throughput (sentences/min)`

---

## ğŸ§© 14. æ¨¡çµ„è¼¸å…¥/è¼¸å‡ºæ‘˜è¦

| æ¨¡çµ„                 | Input              | Output                         |
| ------------------ | ------------------ | ------------------------------ |
| TranslationManager | STT.final_sentence | Translated Sentence + Context  |
| LLMClient          | sentence/context   | translated_text / summary_text |
| ContextManager     | translated_text    | updated_context                |
| DialogueRecorder   | translated_record  | `.jsonl` / `.csv`              |
| LatencyTracker     | start/stop events  | latency_ms                     |
| PromptBuilder      | context + sentence | ready-to-send prompt           |

---

## ğŸ§© 15. æ¨¡çµ„ä¹‹é–“çš„éåŒæ­¥äº‹ä»¶åœ–

```text
STT.final_sentence
   â”‚
   â–¼
TranslationManager â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                             â”‚
   â–¼                             â”‚
 LLMClient (LLM1)                â”‚
   â”‚                             â”‚
   â–¼                             â”‚
 ContextManager (LLM2) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”œâ”€â”€â–º Overlay.update_translation()
   â”œâ”€â”€â–º Overlay.update_context()
   â””â”€â”€â–º DialogueRecorder.append_record()
```


## ğŸ§° 16. ä¾è³´è¨­å®šï¼ˆconfig.jsonï¼‰

```json
{
  "llm_api": "gpt-4.1-mini-2025-04-14",
  "context_tokens": 500,
  "latency_budget_ms": { "total": 1500, "llm": 700 },
  "retry": { "max_attempts": 2, "backoff_ms": 400 },
  "output_format": "jsonl"
}
```

---

## âœ… 17. æ¸¬è©¦æ¸…å–®

* [ ] ç¿»è­¯å»¶é² < 1.5 ç§’
* [ ] Context é•·åº¦ç©©å®š < 500 tokens
* [ ] Context ä¸²æ¥æº–ç¢ºï¼ˆä¸»é¡Œé€£è²«ï¼‰
* [ ] é‡è©¦ç­–ç•¥åœ¨å¤±æ•—æ™‚æ­£ç¢ºè§¸ç™¼
* [ ] Dialogue Log æ ¼å¼æ­£ç¢ºä¸”å¯è¢«é‡æ’­
* [ ] ç¿»è­¯èˆ‡èªå¢ƒæ›´æ–°äº‹ä»¶æ­£ç¢ºé †åºï¼ˆLLM1â†’LLM2ï¼‰

---

## ğŸ§± 18. è¨­è¨ˆç†å¿µæ‘˜è¦

* **èªå¢ƒå°å‘ç¿»è­¯**ï¼šæ¯å¥ç¿»è­¯éƒ½å¸¶å…¥çŸ­ç¯‡èªå¢ƒï¼Œé¿å…ç‰‡æ®µå¼ç›´è­¯ã€‚
* **äº‹ä»¶é©…å‹•éåŒæ­¥è¨­è¨ˆ**ï¼šLLM1 / LLM2 ä¸¦è¡Œè™•ç†ã€æ¸›å°‘å»¶é²ã€‚
* **å¯è§€æ¸¬æ€§**ï¼šå»¶é²ã€token ä½¿ç”¨ã€Context è®ŠåŒ–å…¨è¨˜éŒ„æ–¼ System Logã€‚
* **å¯æ“´å……æ€§**ï¼šå¯æ›¿æ›å…¶ä»– APIï¼ˆGemini / Claudeï¼‰è€Œä¸æ”¹ä¸»æµç¨‹ã€‚
* **å®‰å…¨é™ç´š**ï¼šä»»ä¸€å±¤å¤±æ•—ä¸é˜»å¡ Overlay é¡¯ç¤ºã€‚